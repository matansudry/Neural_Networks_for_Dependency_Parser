{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "\n",
    "# import dill\n",
    "# from tqdm import tqdm\n",
    "# import hyperopt as hpo\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src import utils\n",
    "from src import bilstm\n",
    "import src.dataset as dset\n",
    "import src.pytorch_utils as ptu\n",
    "import src.chu_liu_edmonds as chu\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "versions_dir = 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125430/125430 [00:16<00:00, 7426.20it/s]\n",
      "100%|██████████| 25325/25325 [00:03<00:00, 7499.66it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dset.DataSet('data/train.labeled', tqdm_bar=True, use_glove=False)\n",
    "test_dataset = dset.DataSet('data/test.labeled', train_dataset=train_dataset, tqdm_bar=True, use_glove=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model version: V1_1.1\n",
      "Number of parameters 5130001 trainable 5130001\n"
     ]
    }
   ],
   "source": [
    "version = 'V1_1.1'\n",
    "save = False\n",
    "# save = True\n",
    "\n",
    "model = bilstm.BiLSTM(train_dataset=train_dataset,\n",
    "                      word_embed_dim=300,\n",
    "                      tag_embed_dim=25,\n",
    "                      hidden_dim=125,\n",
    "                      num_layers=2,\n",
    "                      bias=True,\n",
    "                      attention_dim=100,\n",
    "                      lstm_activation=None,\n",
    "                      attn_activation=nn.Tanh(),\n",
    "                      p_dropout=0.1,\n",
    "                      attention=utils.AdditiveAttention,\n",
    "                      softmax=nn.LogSoftmax(dim=2),\n",
    "                      glove=False,\n",
    "                      freeze=False)\n",
    "\n",
    "checkpoint = ptu.Checkpoint(version=version,\n",
    "                            model=model,\n",
    "                            optimizer=torch.optim.Adam,\n",
    "                            criterion=nn.NLLLoss,\n",
    "                            score=lambda y_true, y_pred: (np.array(y_true) == np.array(y_pred)).mean(),\n",
    "                            versions_dir=versions_dir,\n",
    "                            loss_decision_func=utils.loss_decision_func,\n",
    "                            out_decision_func=chu.test_chu_liu_edmonds,\n",
    "                            seed=42,\n",
    "                            custom_run_func=None,\n",
    "                            save=save,\n",
    "                            prints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1/ 20 | train_loss 0.46409 | val_loss 0.52544 | train_score 0.86378 | val_score 0.84354 | train_time   1.23 min *\n",
      "epoch   2/ 20 | train_loss 0.30018 | val_loss 0.46261 | train_score 0.90553 | val_score 0.85562 | train_time   2.60 min *\n",
      "epoch   3/ 20 | train_loss 0.20646 | val_loss 0.47012 | train_score 0.93158 | val_score 0.86158 | train_time   3.90 min *\n",
      "epoch   4/ 20 | train_loss 0.15134 | val_loss 0.48555 | train_score 0.95148 | val_score 0.86709 | train_time   5.23 min *\n",
      "epoch   5/ 20 | train_loss 0.12456 | val_loss 0.51293 | train_score 0.96467 | val_score 0.87420 | train_time   6.53 min *\n",
      "epoch   6/ 20 | train_loss 0.08724 | val_loss 0.52349 | train_score 0.97258 | val_score 0.87490 | train_time   7.94 min *\n",
      "epoch   7/ 20 | train_loss 0.07648 | val_loss 0.56094 | train_score 0.97500 | val_score 0.87375 | train_time   9.22 min\n",
      "epoch   8/ 20 | train_loss 0.05702 | val_loss 0.58352 | train_score 0.98178 | val_score 0.87601 | train_time  10.45 min *\n",
      "epoch   9/ 20 | train_loss 0.05145 | val_loss 0.64754 | train_score 0.98324 | val_score 0.88004 | train_time  11.88 min *\n",
      "epoch  10/ 20 | train_loss 0.04631 | val_loss 0.63245 | train_score 0.98522 | val_score 0.87926 | train_time  13.15 min\n",
      "epoch  11/ 20 | train_loss 0.04353 | val_loss 0.65534 | train_score 0.98688 | val_score 0.87864 | train_time  14.61 min\n",
      "epoch  12/ 20 | train_loss 0.03083 | val_loss 0.68151 | train_score 0.99019 | val_score 0.88103 | train_time  15.84 min *\n",
      "epoch  13/ 20 | train_loss 0.03862 | val_loss 0.66798 | train_score 0.98767 | val_score 0.87860 | train_time  17.16 min\n",
      "epoch  14/ 20 | train_loss 0.03479 | val_loss 0.69229 | train_score 0.98920 | val_score 0.87708 | train_time  18.38 min\n",
      "epoch  15/ 20 | train_loss 0.02760 | val_loss 0.70169 | train_score 0.99189 | val_score 0.88292 | train_time  19.61 min *\n",
      "epoch  16/ 20 | train_loss 0.02980 | val_loss 0.71912 | train_score 0.99156 | val_score 0.88132 | train_time  21.06 min\n",
      "epoch  17/ 20 | train_loss 0.02379 | val_loss 0.72858 | train_score 0.99261 | val_score 0.88321 | train_time  22.29 min *\n",
      "epoch  18/ 20 | train_loss 0.02806 | val_loss 0.76856 | train_score 0.99227 | val_score 0.88127 | train_time  23.57 min\n",
      "epoch  19/ 20 | train_loss 0.02137 | val_loss 0.71329 | train_score 0.99306 | val_score 0.88654 | train_time  24.79 min *\n",
      "epoch  20/ 20 | train_loss 0.02150 | val_loss 0.76993 | train_score 0.99307 | val_score 0.88156 | train_time  26.06 min\n",
      "epoch  21/ 40 | train_loss 0.02557 | val_loss 0.76770 | train_score 0.99190 | val_score 0.88173 | train_time  27.27 min\n",
      "epoch  22/ 40 | train_loss 0.01290 | val_loss 0.74119 | train_score 0.99609 | val_score 0.88691 | train_time  28.49 min *\n",
      "epoch  23/ 40 | train_loss 0.00615 | val_loss 0.75670 | train_score 0.99846 | val_score 0.89003 | train_time  29.77 min *\n",
      "epoch  24/ 40 | train_loss 0.00291 | val_loss 0.80120 | train_score 0.99927 | val_score 0.89057 | train_time  31.05 min *\n",
      "epoch  25/ 40 | train_loss 0.00162 | val_loss 0.81223 | train_score 0.99963 | val_score 0.88970 | train_time  32.31 min\n",
      "epoch  26/ 40 | train_loss 0.00117 | val_loss 0.82889 | train_score 0.99973 | val_score 0.89061 | train_time  33.59 min *\n",
      "epoch  27/ 40 | train_loss 0.00130 | val_loss 0.83142 | train_score 0.99962 | val_score 0.89036 | train_time  34.91 min\n",
      "epoch  28/ 40 | train_loss 0.00091 | val_loss 0.83847 | train_score 0.99974 | val_score 0.89250 | train_time  36.12 min *\n",
      "epoch  29/ 40 | train_loss 0.00062 | val_loss 0.85438 | train_score 0.99982 | val_score 0.89254 | train_time  37.44 min *\n",
      "epoch  30/ 40 | train_loss 0.00052 | val_loss 0.86979 | train_score 0.99985 | val_score 0.89221 | train_time  38.70 min\n",
      "epoch  31/ 40 | train_loss 0.00046 | val_loss 0.87446 | train_score 0.99988 | val_score 0.89283 | train_time  39.94 min *\n",
      "epoch  32/ 40 | train_loss 0.00038 | val_loss 0.88435 | train_score 0.99987 | val_score 0.89180 | train_time  41.24 min\n",
      "epoch  33/ 40 | train_loss 0.00038 | val_loss 0.88808 | train_score 0.99986 | val_score 0.89176 | train_time  42.46 min\n",
      "epoch  34/ 40 | train_loss 0.00035 | val_loss 0.88828 | train_score 0.99988 | val_score 0.89205 | train_time  43.68 min\n",
      "epoch  35/ 40 | train_loss 0.00032 | val_loss 0.89565 | train_score 0.99989 | val_score 0.89122 | train_time  44.91 min\n",
      "epoch  36/ 40 | train_loss 0.00031 | val_loss 0.89990 | train_score 0.99988 | val_score 0.89159 | train_time  46.15 min\n",
      "epoch  37/ 40 | train_loss 0.00029 | val_loss 0.90000 | train_score 0.99989 | val_score 0.89143 | train_time  47.35 min\n",
      "epoch  38/ 40 | train_loss 0.00028 | val_loss 0.90310 | train_score 0.99990 | val_score 0.89172 | train_time  48.57 min\n",
      "epoch  39/ 40 | train_loss 0.00028 | val_loss 0.90587 | train_score 0.99991 | val_score 0.89176 | train_time  49.80 min\n",
      "epoch  40/ 40 | train_loss 0.00027 | val_loss 0.90714 | train_score 0.99991 | val_score 0.89168 | train_time  51.03 min\n",
      "epoch  41/ 60 | train_loss 0.00183 | val_loss 0.92542 | train_score 0.99946 | val_score 0.89077 | train_time  52.24 min\n",
      "epoch  42/ 60 | train_loss 0.00168 | val_loss 0.92986 | train_score 0.99944 | val_score 0.89061 | train_time  53.46 min\n",
      "epoch  43/ 60 | train_loss 0.00089 | val_loss 0.90856 | train_score 0.99973 | val_score 0.89143 | train_time  54.68 min\n",
      "epoch  44/ 60 | train_loss 0.00058 | val_loss 0.91678 | train_score 0.99983 | val_score 0.89168 | train_time  56.04 min\n",
      "epoch  45/ 60 | train_loss 0.00062 | val_loss 0.92049 | train_score 0.99983 | val_score 0.89217 | train_time  57.28 min\n",
      "epoch  46/ 60 | train_loss 0.00050 | val_loss 0.92565 | train_score 0.99982 | val_score 0.89176 | train_time  58.59 min\n",
      "epoch  47/ 60 | train_loss 0.00064 | val_loss 0.92428 | train_score 0.99978 | val_score 0.89246 | train_time  59.80 min\n",
      "epoch  48/ 60 | train_loss 0.00058 | val_loss 0.94751 | train_score 0.99982 | val_score 0.89184 | train_time  61.01 min\n",
      "epoch  49/ 60 | train_loss 0.00055 | val_loss 0.97043 | train_score 0.99983 | val_score 0.89139 | train_time  62.21 min\n",
      "epoch  50/ 60 | train_loss 0.00048 | val_loss 0.95702 | train_score 0.99985 | val_score 0.89192 | train_time  63.43 min\n",
      "epoch  51/ 60 | train_loss 0.00083 | val_loss 0.94967 | train_score 0.99977 | val_score 0.89085 | train_time  64.66 min\n",
      "epoch  52/ 60 | train_loss 0.00045 | val_loss 0.94732 | train_score 0.99985 | val_score 0.89032 | train_time  65.88 min\n",
      "epoch  53/ 60 | train_loss 0.00057 | val_loss 0.94528 | train_score 0.99983 | val_score 0.88991 | train_time  67.08 min\n",
      "epoch  54/ 60 | train_loss 0.00068 | val_loss 0.97730 | train_score 0.99980 | val_score 0.89077 | train_time  68.28 min\n",
      "epoch  55/ 60 | train_loss 0.00075 | val_loss 0.97143 | train_score 0.99978 | val_score 0.89221 | train_time  69.49 min\n",
      "epoch  56/ 60 | train_loss 0.00092 | val_loss 1.01177 | train_score 0.99960 | val_score 0.88991 | train_time  70.72 min\n",
      "epoch  57/ 60 | train_loss 0.00035 | val_loss 0.96086 | train_score 0.99984 | val_score 0.89213 | train_time  71.94 min\n",
      "epoch  58/ 60 | train_loss 0.00024 | val_loss 0.97179 | train_score 0.99990 | val_score 0.89221 | train_time  73.16 min\n",
      "epoch  59/ 60 | train_loss 0.00023 | val_loss 0.98474 | train_score 0.99989 | val_score 0.89143 | train_time  74.38 min\n",
      "epoch  60/ 60 | train_loss 0.00070 | val_loss 1.00446 | train_score 0.99978 | val_score 0.89052 | train_time  75.60 min\n"
     ]
    }
   ],
   "source": [
    "word_dropout_alpha = 0.25\n",
    "hyperparam_list = [\n",
    "    {'train_epochs': 20, 'batch_size': 8, 'optimizer_params': {'lr': 2e-3, 'weight_decay': 5e-7}},\n",
    "    {'train_epochs': 20, 'batch_size': 8, 'optimizer_params': {'lr': 2e-3, 'weight_decay': 1e-6}, 'lr_decay': 0.2},\n",
    "    {'train_epochs': 20, 'batch_size': 8, 'optimizer_params': {'lr': 4e-4, 'weight_decay': 0.0}},\n",
    "]\n",
    "\n",
    "for session in hyperparam_list:\n",
    "    checkpoint.train(device=device,\n",
    "                     train_dataset=train_dataset.dataset(word_dropout_alpha, train=True),\n",
    "                     val_dataset=test_dataset.dataset(train=False),\n",
    "                     prints=True,\n",
    "                     epochs_save=5,\n",
    "                     save=save,\n",
    "                     **session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_trials = hpo.Trials()\n",
    "# init_log = pd.DataFrame(columns=['timestamp', 'test_score', 'space'] + list(init_space.keys()))\n",
    "\n",
    "with open(os.path.join(versions_dir, version, 'trials.pth'), \"rb\") as f:\n",
    "    init_trials = dill.load(f)\n",
    "init_log = pd.read_csv(os.path.join(versions_dir, version, 'trials_log.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_space = dict(sorted(list({\n",
    "    'train_epochs': 5,\n",
    "    'batch_size': hpo.hp.quniform('batch_size', low=3, high=5, q=1),  # 8-16-32\n",
    "    'optimizer__lr': hpo.hp.uniform('optimizer__lr', low=1e-4, high=1e-3),\n",
    "    'optimizer__wd': 0.0, # hpo.hp.choice('optimizer__wd_ind', [0, hpo.hp.uniform('optimizer__wd', low=0, high=1e-5)]),\n",
    "    'bias': hpo.hp.choice('bias', [True, False]),\n",
    "    \n",
    "    'word_embed_dim': 100,  # 300\n",
    "    'tag_embed_dim': 25,  # hpo.hp.quniform('tag_embed_dim', low=30, high=50, q=4)\n",
    "    'hidden_dim': 125,  # hpo.hp.quniform('hidden_dim', low=100, high=400, q=50)\n",
    "    'num_layers': 2,  # hpo.hp.quniform('num_layers', low=2, high=4, q=1)\n",
    "    'mlp1_dim': 100,  # hpo.hp.quniform('mlp1_dim', low=100, high=400, q=50)\n",
    "    'p_dropout': 0.1,  # hpo.hp.normal('p_dropout', mu=0.2, sigma=0.1)\n",
    "    'word_dropout': 0.25,  # hpo.hp.normal('word_dropout', mu=0.3, sigma=0.1)\n",
    "}.items()), key=lambda x: x[0]))\n",
    "\n",
    "def init_objective(space, save=False):\n",
    "    display(space)\n",
    "    last_score = init_log['test_score'].max() if len(init_log) > 0 else 0.0\n",
    "#     print('last_score', last_score)\n",
    "    batch_size = min(len(train_dataset.dataset), int(2 ** space['batch_size']))\n",
    "    p_dropout = max(0.0, min(0.7, space['p_dropout']))\n",
    "    word_dropout = max(0.0, min(0.7, space['word_dropout']))\n",
    "\n",
    "    model = m1.BiLSTM(train_dataset=train_dataset,\n",
    "                      word_embed_dim=100,\n",
    "                      tag_embed_dim=space['tag_embed_dim'],\n",
    "                      hidden_dim=space['hidden_dim'],\n",
    "                      num_layers=space['mlp1_dim'],\n",
    "                      bias=space['bias'],\n",
    "                      mlp1_dim=space['mlp1_dim'],\n",
    "                      p_dropout=p_dropout,\n",
    "                      word_dropout=word_dropout)\n",
    "\n",
    "    init_checkpoint = ptu.Checkpoint(version=version,\n",
    "                                     model=model,\n",
    "                                     optimizer=torch.optim.Adam,\n",
    "                                     criterion=nn.NLLLoss,\n",
    "                                     score=lambda y_true, y_pred: (np.array(y_true) == np.array(y_pred)).mean(),\n",
    "                                     versions_dir=versions_dir,\n",
    "                                     loss_decision_func=utils.loss_decision_func,\n",
    "                                     out_decision_func=lambda y_pred, flat_y_pred, mask, padding: flat_y_pred.argmax(axis=1),\n",
    "                                     seed=42,\n",
    "                                     custom_run_func=None,\n",
    "                                     save=save,\n",
    "                                     prints=False)\n",
    "    \n",
    "    init_checkpoint.train(device=device,\n",
    "                          train_dataset=train_dataset.dataset,\n",
    "                          val_dataset=test_dataset.dataset,\n",
    "                          train_epochs=space['train_epochs'],\n",
    "                          batch_size=batch_size,\n",
    "                          optimizer_params={\n",
    "                              'lr': space['optimizer__lr'],\n",
    "                              'weight_decay': space['optimizer__wd'],\n",
    "                          },\n",
    "                          prints=True,\n",
    "                          epochs_save=0,\n",
    "                          save=save)\n",
    "    \n",
    "    test_score = init_checkpoint.get_log(col='val_score', epoch=-1)\n",
    "#     print('test_score', test_score)\n",
    "    ###############################################################\n",
    "    if test_score > last_score:\n",
    "        init_checkpoint.save(epoch=True)\n",
    "    init_log.loc[init_log.index.max() + 1 if len(init_log) > 0 else 0] = [time.strftime('%d-%m-%Y %H:%M:%S'), test_score, space] + list(space.values())\n",
    "    return -test_score\n",
    "\n",
    "# session_space = dict(sorted(list({\n",
    "#     'train_epochs': 5,\n",
    "#     'batch_size_mult': min(len(X_train), int(2**hpo.hp.quniform('batch_size_mult', low=5, high=9, q=1))),\n",
    "#     'optimizer__lr_mult': hpo.hp.uniform('optimizer__lr_mult', low=1e-5, high=1e-3),\n",
    "#     'optimizer__weight_decay': hpo.hp.uniform('optimizer__weight_decay', low=1e-5, high=1e-3),\n",
    "#     'p_dropout': max(0.0, min(0.9, hpo.hp.normal('p_dropout', mu=0.5, sigma=0.15))),\n",
    "# }.items()), key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 18/500 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_size': 3.0,\n",
       " 'bias': True,\n",
       " 'hidden_dim': 125,\n",
       " 'mlp1_dim': 100,\n",
       " 'num_layers': 2,\n",
       " 'optimizer__lr': 0.0007752413054159258,\n",
       " 'optimizer__wd': 0.0,\n",
       " 'p_dropout': 0.1,\n",
       " 'tag_embed_dim': 25,\n",
       " 'train_epochs': 5,\n",
       " 'word_dropout': 0.25,\n",
       " 'word_embed_dim': 100}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 18/500 [00:06<03:03,  2.63trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-3d320fd4212b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m              \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_trials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m              \u001b[0mmax_queue_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m              max_evals=iters)\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/nlp_hw2/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m         )\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp_hw2/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         )\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp_hw2/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp_hw2/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp_hw2/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp_hw2/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp_hw2/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             )\n\u001b[0;32m--> 894\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-1fc560d71469>\u001b[0m in \u001b[0;36minit_objective\u001b[0;34m(space, save)\u001b[0m\n\u001b[1;32m     57\u001b[0m                           \u001b[0mprints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                           \u001b[0mepochs_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                           save=save)\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mtest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_checkpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Neural_Networks_for_Dependency_Parser/src/pytorch_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, device, train_dataset, val_dataset, train_epochs, batch_size, optimizer_params, prints, p_dropout, epochs_save, lr_decay, save)\u001b[0m\n\u001b[1;32m    497\u001b[0m                         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_run_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m                         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Neural_Networks_for_Dependency_Parser/src/pytorch_utils.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, device, data_loader, train, results, decision_func)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp_hw2/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nlp_hw2/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iters = 500\n",
    "\n",
    "_ = hpo.fmin(init_objective,\n",
    "             init_space,\n",
    "             algo=hpo.tpe.suggest,\n",
    "             trials=init_trials,\n",
    "             max_queue_len=1,\n",
    "             max_evals=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(versions_dir, version, 'trials.pth'), 'wb') as f:\n",
    "    dill.dump(init_trials, f)\n",
    "    \n",
    "init_log.to_csv(os.path.join(versions_dir, version, 'trials_log.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0016\n",
      "0.0012800000000000003\n",
      "0.0010240000000000002\n",
      "0.0008192000000000002\n",
      "0.0006553600000000002\n",
      "0.0005242880000000002\n",
      "0.0004194304000000002\n",
      "0.0003355443200000002\n",
      "0.00026843545600000016\n",
      "0.00021474836480000011\n",
      "0.0001717986918400001\n",
      "0.0001374389534720001\n",
      "0.00010995116277760008\n",
      "8.796093022208007e-05\n",
      "7.036874417766406e-05\n"
     ]
    }
   ],
   "source": [
    "init_lr = 2e-3\n",
    "decay = (1 - 0.2)\n",
    "for i in range(15):\n",
    "    print('{}'.format(init_lr*(decay ** (i+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_hw2",
   "language": "python",
   "name": "nlp_hw2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
