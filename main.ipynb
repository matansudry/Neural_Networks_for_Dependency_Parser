{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import src.pytorch_utils as ptu\n",
    "import src.dataset as dset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "models_path = 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125430/125430 [00:17<00:00, 7108.94it/s]\n",
      "100%|██████████| 25325/25325 [00:03<00:00, 7357.59it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dset.DataSet('data/train.labeled', tqdm_bar=True)\n",
    "# train_dataset = dset.DataSet('data/test.labeled', tqdm_bar=True)\n",
    "test_dataset = dset.DataSet('data/test.labeled', train_dataset=train_dataset, tqdm_bar=True)\n",
    "# comp_dataset = dset.DataSet('data/comp.unlabeled', train_dataset=train_dataset, tagged=False, tqdm_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, train_dataset, word_embed_dim, tag_embed_dim, hidden_dim, num_layers, bias, mlp1_dim, mlp2_dim, p_dropout):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        \n",
    "        self.pad = int(train_dataset.special_dict[dset.PAD])\n",
    "        self.y_pad = int(train_dataset.special_dict[dset.y_PAD])\n",
    "\n",
    "        self.word_embedding_layer = nn.Embedding(num_embeddings=train_dataset.words_num,\n",
    "                                                 embedding_dim=word_embed_dim,\n",
    "                                                 padding_idx=self.pad)\n",
    "\n",
    "        self.tag_embedding_layer = nn.Embedding(num_embeddings=train_dataset.tags_num,\n",
    "                                                embedding_dim=tag_embed_dim,\n",
    "                                                padding_idx=self.pad)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=word_embed_dim + tag_embed_dim,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            num_layers=num_layers,\n",
    "                            bias=bias,\n",
    "                            dropout=p_dropout,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "\n",
    "        self.mlp1 = nn.Linear(int(hidden_dim*2),\n",
    "                              mlp1_dim,\n",
    "                              bias=bias)\n",
    "\n",
    "        self.mlp2 = nn.Linear(mlp1_dim,\n",
    "                              mlp2_dim,\n",
    "                              bias=bias)\n",
    "\n",
    "    def forward(self, words, tags, lens, prints=False):\n",
    "        max_len = words.shape[1]\n",
    "        \n",
    "        print('words', words.shape) if prints else None\n",
    "        # [batch_size, max_sentence_len]\n",
    "        \n",
    "        print('tags', tags.shape) if prints else None\n",
    "        # [batch_size, max_sentence_len]\n",
    "        \n",
    "        print('lens', len(lens)) if prints else None\n",
    "        # [batch_size]\n",
    "        \n",
    "        words = self.word_embedding_layer(words)\n",
    "        print('word_embeds', words.shape) if prints else None\n",
    "        # [batch_size, max_sentence_len, word_embed_dim]\n",
    "\n",
    "        tags = self.tag_embedding_layer(tags)\n",
    "        print('tag_embeds', tags.shape) if prints else None\n",
    "        # [batch_size, max_sentence_len, tag_embed_dim]\n",
    "        \n",
    "        x = torch.cat((words, tags), -1)\n",
    "        print('cat', x.shape) if prints else None\n",
    "        # [batch_size, max_sentence_len, word_embed_dim + tag_embed_dim]\n",
    "        \n",
    "        x = nn.utils.rnn.pack_padded_sequence(x, lens, batch_first=True, enforce_sorted=False)\n",
    "#         print('pack_padded_sequence', x.shape) if prints else None\n",
    "        # [batch_size, packed_size, word_embed_dim + tag_embed_dim]\n",
    "        \n",
    "        x, _ = self.lstm(x)\n",
    "#         print('lstm', x.shape) if prints else None\n",
    "        # [batch_size, seq_length, 2*hidden_dim]\n",
    "        \n",
    "        x, lens = nn.utils.rnn.pad_packed_sequence(x, batch_first=True, padding_value=self.pad, total_length=max_len)#.transpose(1, 0)\n",
    "        print('pad_packed_sequence', x.shape) if prints else None\n",
    "        # [batch_size, packed_size, word_embed_dim + tag_embed_dim]\n",
    "\n",
    "        x = self.mlp1(x)\n",
    "        print('mlp1', x.shape) if prints else None\n",
    "        # [batch_size, max_sentence_len, mlp1_dim]\n",
    "        \n",
    "        x = F.tanh(x)\n",
    "        print('mlp1_tanh', x.shape) if prints else None\n",
    "        # [batch_size, max_sentence_len, mlp1_dim]\n",
    "        \n",
    "        x = self.mlp2(x)\n",
    "        print('mlp2', x.shape) if prints else None\n",
    "        # [batch_size, max_sentence_len, mlp2_dim]\n",
    "        \n",
    "        x = F.log_softmax(x, dim=2)\n",
    "        print('log_softmax', x.shape) if prints else None\n",
    "        # [batch_size, max_sentence_len, mlp2_dim]\n",
    "        \n",
    "        x = x.transpose(2, 1)\n",
    "        print('transpose', x.shape) if prints else None\n",
    "        # [batch_size, mlp2_dim, max_sentence_len]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_decision_func(obj, device, batch, prints=False):\n",
    "    words, tags, lens, y = batch\n",
    "    out = obj.model.forward(words.to(device), tags.to(device), lens, prints=prints)\n",
    "    mask = (y > obj.model.y_pad).int()\n",
    "    \n",
    "    out = out.transpose(2, 1)[mask == 1.]\n",
    "    y = y[mask == 1.]\n",
    "    loss = obj.criterion(out.to(device), y.to(device).long())\n",
    "    return loss, y, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model version: V1_1.0\n",
      "Number of parameters 2096925 trainable 2096925\n"
     ]
    }
   ],
   "source": [
    "version = 'V1_1.0'\n",
    "\n",
    "model = BiLSTM(train_dataset=train_dataset,\n",
    "               word_embed_dim=100,  # 100\n",
    "               tag_embed_dim=25,  # 25\n",
    "               hidden_dim=125,  # 125\n",
    "               num_layers=2,  # 2\n",
    "               bias=True,\n",
    "               mlp1_dim=100,  # 100\n",
    "               mlp2_dim=250,  # 100\n",
    "               p_dropout=0.5)  # 0.1\n",
    "\n",
    "checkpoint = ptu.Checkpoint(models_path=models_path,\n",
    "                            version=version,\n",
    "                            model=model,\n",
    "                            score=lambda y_true, y_pred: (np.array(y_true) == np.array(y_pred)).mean(),\n",
    "                            loss_decision_func=loss_decision_func,\n",
    "                            out_decision_func=lambda x: x.argmax(axis=1),\n",
    "                            seed=42,\n",
    "                            optimizer=torch.optim.Adam,\n",
    "                            criterion=nn.NLLLoss,\n",
    "                            save=True,\n",
    "                            prints=True,\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  38/ 87 | train_loss 1.20024 | val_loss 1.35806 | train_score 0.70074 | val_score 0.64785 | train_time   3.34 min\n",
      "epoch  39/ 87 | train_loss 1.19707 | val_loss 1.35706 | train_score 0.70378 | val_score 0.64962 | train_time   3.40 min\n",
      "epoch  40/ 87 | train_loss 1.19196 | val_loss 1.35303 | train_score 0.70341 | val_score 0.64822 | train_time   3.51 min\n",
      "epoch  41/ 87 | train_loss 1.18825 | val_loss 1.35143 | train_score 0.70789 | val_score 0.65180 | train_time   3.61 min\n",
      "epoch  42/ 87 | train_loss 1.18508 | val_loss 1.34978 | train_score 0.71030 | val_score 0.65287 | train_time   3.66 min\n",
      "epoch  43/ 87 | train_loss 1.18216 | val_loss 1.34754 | train_score 0.71097 | val_score 0.65266 | train_time   3.76 min\n",
      "epoch  44/ 87 | train_loss 1.17999 | val_loss 1.34642 | train_score 0.71398 | val_score 0.65538 | train_time   3.81 min\n",
      "epoch  45/ 87 | train_loss 1.17790 | val_loss 1.34565 | train_score 0.71329 | val_score 0.65521 | train_time   3.91 min\n",
      "epoch  46/ 87 | train_loss 1.17650 | val_loss 1.34570 | train_score 0.71541 | val_score 0.65607 | train_time   4.01 min\n",
      "epoch  47/ 87 | train_loss 1.17432 | val_loss 1.34413 | train_score 0.71451 | val_score 0.65595 | train_time   4.07 min\n",
      "epoch  48/ 87 | train_loss 1.17299 | val_loss 1.34370 | train_score 0.71598 | val_score 0.65723 | train_time   4.12 min\n",
      "epoch  49/ 87 | train_loss 1.17155 | val_loss 1.34284 | train_score 0.71570 | val_score 0.65698 | train_time   4.19 min\n",
      "epoch  50/ 87 | train_loss 1.17063 | val_loss 1.34270 | train_score 0.71596 | val_score 0.65677 | train_time   4.24 min\n",
      "epoch  51/ 87 | train_loss 1.16979 | val_loss 1.34270 | train_score 0.71707 | val_score 0.65665 | train_time   4.35 min\n",
      "epoch  52/ 87 | train_loss 1.16811 | val_loss 1.34118 | train_score 0.71696 | val_score 0.65649 | train_time   4.40 min\n",
      "epoch  53/ 87 | train_loss 1.16703 | val_loss 1.34057 | train_score 0.71903 | val_score 0.65871 | train_time   4.45 min\n",
      "epoch  54/ 87 | train_loss 1.16601 | val_loss 1.34000 | train_score 0.71927 | val_score 0.65908 | train_time   4.54 min\n",
      "epoch  55/ 87 | train_loss 1.16519 | val_loss 1.33976 | train_score 0.71845 | val_score 0.65760 | train_time   4.60 min\n",
      "epoch  56/ 87 | train_loss 1.16465 | val_loss 1.33987 | train_score 0.71843 | val_score 0.65760 | train_time   4.66 min\n",
      "epoch  57/ 87 | train_loss 1.16427 | val_loss 1.33998 | train_score 0.71936 | val_score 0.65821 | train_time   4.72 min\n",
      "epoch  58/ 87 | train_loss 1.16360 | val_loss 1.33943 | train_score 0.71903 | val_score 0.65764 | train_time   4.77 min\n",
      "epoch  59/ 87 | train_loss 1.16296 | val_loss 1.33890 | train_score 0.71876 | val_score 0.65760 | train_time   4.83 min\n",
      "epoch  60/ 87 | train_loss 1.16250 | val_loss 1.33881 | train_score 0.71935 | val_score 0.65739 | train_time   4.88 min\n",
      "epoch  61/ 87 | train_loss 1.16200 | val_loss 1.33866 | train_score 0.72016 | val_score 0.65883 | train_time   4.94 min\n",
      "epoch  62/ 87 | train_loss 1.16122 | val_loss 1.33805 | train_score 0.71979 | val_score 0.65887 | train_time   4.99 min\n",
      "epoch  63/ 87 | train_loss 1.16068 | val_loss 1.33768 | train_score 0.71975 | val_score 0.65846 | train_time   5.05 min\n",
      "epoch  64/ 87 | train_loss 1.16038 | val_loss 1.33765 | train_score 0.71993 | val_score 0.65912 | train_time   5.10 min\n",
      "epoch  65/ 87 | train_loss 1.16022 | val_loss 1.33781 | train_score 0.72034 | val_score 0.65932 | train_time   5.16 min\n",
      "epoch  66/ 87 | train_loss 1.16005 | val_loss 1.33793 | train_score 0.72035 | val_score 0.65899 | train_time   5.32 min\n",
      "epoch  67/ 87 | train_loss 1.15976 | val_loss 1.33777 | train_score 0.72010 | val_score 0.65899 | train_time   5.37 min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a8600ef68ce0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                      \u001b[0mepochs_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                      \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                      **session)\n\u001b[0m",
      "\u001b[0;32m~/Neural_Networks_for_Dependency_Parser/src/pytorch_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, device, train_dataset, val_dataset, train_epochs, batch_size, optimizer_params, prints, p_dropout, epochs_save, lr_decay, save)\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0;31m# train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Neural_Networks_for_Dependency_Parser/src/pytorch_utils.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, device, data_loader, train)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_decision_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-38f7fc231778>\u001b[0m in \u001b[0;36mloss_decision_func\u001b[0;34m(obj, device, batch, prints)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperparam_list = [\n",
    "#     {'train_epochs': 5, 'batch_size': 32, 'optimizer_params': {'lr': 1e-3,}, 'lr_decay': 0.0},\n",
    "#     {'train_epochs': 5, 'batch_size': 64, 'optimizer_params': {'lr': 4e-4}, 'lr_decay': 0.07},\n",
    "#     {'train_epochs': 5, 'batch_size': 128, 'optimizer_params': {}, 'lr_decay': 0.07},\n",
    "#     {'train_epochs': 5, 'batch_size': 1024, 'optimizer_params': {'weight_decay': 1e-6}, 'lr_decay': 0.07},\n",
    "    {'train_epochs': 50, 'batch_size': 2048, 'optimizer_params': {'weight_decay': 1e-6}, 'lr_decay': 0.07},\n",
    "#     {'train_epochs': 50, 'batch_size': 5000, 'optimizer_params': {'weight_decay': 0}, 'lr_decay': 0.05},\n",
    "#     {'train_epochs': 10, 'batch_size': 32, 'optimizer_params': {'lr': 1e-4, 'weight_decay': 0}, 'p_dropout': 0.5, 'lr_decay': 0.07},\n",
    "#     {'train_epochs': 10, 'batch_size': 64, 'optimizer_params': {'lr': 1e-5, 'weight_decay': 0}, 'p_dropout': 0.5, 'lr_decay': 0.07},\n",
    "#     {'train_epochs': 10, 'batch_size': 128, 'optimizer_params': {'lr': 1e-6, 'weight_decay': 0}, 'p_dropout': 0.5, 'lr_decay': 0.07},\n",
    "]\n",
    "\n",
    "for session in hyperparam_list:\n",
    "    checkpoint.train(device=device,\n",
    "                     train_dataset=train_dataset.dataset,\n",
    "                     val_dataset=test_dataset.dataset,\n",
    "                     prints=True,\n",
    "                     epochs_save=5,\n",
    "                     save=True,\n",
    "                     **session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt as hpo\n",
    "\n",
    "def Counter():\n",
    "    for i in range(999999999999):\n",
    "        yield i\n",
    "\n",
    "init_space = {\n",
    "    \n",
    "}\n",
    "\n",
    "session_space = {\n",
    "    \n",
    "}\n",
    "\n",
    "def init_objective(space, save=False):\n",
    "    score = 0.0\n",
    "    return - score\n",
    "\n",
    "def session_objective(space, save=False):\n",
    "    score = 0.0\n",
    "    return - score\n",
    "\n",
    "_ = hpo.fmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words torch.Size([32, 249])\n",
      "tags torch.Size([32, 249])\n",
      "lens 32\n",
      "word_embeds torch.Size([32, 249, 300])\n",
      "tag_embeds torch.Size([32, 249, 25])\n",
      "cat torch.Size([32, 249, 325])\n",
      "pad_packed_sequence torch.Size([32, 249, 500])\n",
      "mlp1 torch.Size([32, 249, 100])\n",
      "mlp1_tanh torch.Size([32, 249, 100])\n",
      "mlp2 torch.Size([32, 249, 250])\n",
      "log_softmax torch.Size([32, 249, 250])\n",
      "transpose torch.Size([32, 250, 249])\n"
     ]
    }
   ],
   "source": [
    "checkpoint.model = checkpoint.model.to(device)\n",
    "checkpoint.model.train()\n",
    "\n",
    "loss_sum = np.array([])\n",
    "y_pred = np.array([])\n",
    "y_true = np.array([])\n",
    "\n",
    "counter = 0\n",
    "loader = torch.utils.data.DataLoader(dataset=train_dataset.dataset, batch_size=32, shuffle=True)\n",
    "for batch in loader:\n",
    "    \n",
    "    loss, y, out = loss_decision_func(checkpoint, device, batch, prints=True)\n",
    "\n",
    "    loss_sum = np.append(loss_sum, float(loss.data))\n",
    "    \n",
    "    y_pred = np.append(y_pred, checkpoint.out_decision_func(out.detach().cpu().numpy()))\n",
    "    \n",
    "    y_true = np.append(y_true, batch[-1].detach().cpu().numpy())\n",
    "    break\n",
    "    counter += 1\n",
    "    if counter > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (mask.sum(dim=1) != lens).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask[mask == 1.].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.transpose(2, 1)[mask == 1.].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### matan's code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset class, need to review and keep only the relevant\n",
    "class Dependency_Parser_Dataset(nn.Module):\n",
    "    def __init__(self, word_dict, pos_dict, dir_path: str, subset: str, \n",
    "                 padding=False, word_embeddings=None):\n",
    "        super().__init__()\n",
    "        self.subset = subset # One of the following: [train, test]\n",
    "        self.file = dir_path + subset + \".wtag\"\n",
    "        self.datareader = PosDataReader(self.file, word_dict, pos_dict)\n",
    "        self.vocab_size = len(self.datareader.word_dict)\n",
    "        if word_embeddings:\n",
    "            self.word_idx_mappings, self.idx_word_mappings, self.word_vectors = word_embeddings\n",
    "        else:\n",
    "            self.word_idx_mappings, self.idx_word_mappings, self.word_vectors = ## need to add our word emb hereself.init_word_embeddings(self.datareader.word_dict)\n",
    "        self.pos_idx_mappings, self.idx_pos_mappings = ## need to add our word emb here self.init_pos_vocab(self.datareader.pos_dict)\n",
    "        \n",
    "        self.pad_idx = self.word_idx_mappings.get(PAD_TOKEN)\n",
    "        self.unknown_idx = self.word_idx_mappings.get(UNKNOWN_TOKEN)\n",
    "        self.word_vector_dim = self.word_vectors.size(-1)\n",
    "        self.sentence_lens = [len(sentence) for sentence in self.datareader.sentences]\n",
    "        self.max_seq_len = max(self.sentence_lens)\n",
    "        self.sentences_dataset = self.convert_sentences_to_dataset(padding)\n",
    "    \n",
    "    def get_word_embeddings(self):\n",
    "        return self.word_idx_mappings, self.idx_word_mappings, self.word_vectors\n",
    "\n",
    "    \n",
    "    def init_pos_vocab(self, pos_dict):\n",
    "        idx_pos_mappings = sorted([self.word_idx_mappings.get(token) for token in SPECIAL_TOKENS])\n",
    "        pos_idx_mappings = {self.idx_word_mappings[idx]: idx for idx in idx_pos_mappings}\n",
    "        \n",
    "        \n",
    "    def convert_sentences_to_dataset(self, padding):\n",
    "        sentence_word_idx_list = list()\n",
    "        sentence_pos_idx_list = list()\n",
    "        sentence_len_list = list()\n",
    "        for sentence_idx, sentence in enumerate(self.datareader.sentences):\n",
    "            words_idx_list = []\n",
    "            pos_idx_list = []\n",
    "            for word, pos in sentence:\n",
    "                words_idx_list.append(self.word_idx_mappings.get(word))\n",
    "                pos_idx_list.append(self.pos_idx_mappings.get(pos))\n",
    "            sentence_len = len(words_idx_list)\n",
    "            # if padding:\n",
    "            #     while len(words_idx_list) < self.max_seq_len:\n",
    "            #         words_idx_list.append(self.word_idx_mappings.get(PAD_TOKEN))\n",
    "            #         pos_idx_list.append(self.pos_idx_mappings.get(PAD_TOKEN))\n",
    "            sentence_word_idx_list.append(torch.tensor(words_idx_list, dtype=torch.long, requires_grad=False))\n",
    "            sentence_pos_idx_list.append(torch.tensor(pos_idx_list, dtype=torch.long, requires_grad=False))\n",
    "            sentence_len_list.append(sentence_len)\n",
    "        \n",
    "        # if padding:\n",
    "        #     all_sentence_word_idx = torch.tensor(sentence_word_idx_list, dtype=torch.long)\n",
    "        #     all_sentence_pos_idx = torch.tensor(sentence_pos_idx_list, dtype=torch.long)\n",
    "        #     all_sentence_len = torch.tensor(sentence_len_list, dtype=torch.long, requires_grad=False)\n",
    "        #     return TensorDataset(all_sentence_word_idx, all_sentence_pos_idx, all_sentence_len)\n",
    "            \n",
    "        return {i: sample_tuple for i, sample_tuple in enumerate(zip(sentence_word_idx_list,\n",
    "                                                                     sentence_pos_idx_list,\n",
    "                                                                     sentence_len_list))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## our model\n",
    "class Dnn_Dependency_Parser(nn.Module):\n",
    "    def __init__(self, word_embeddings, hidden_dim, word_vocab_size, tag_vocab_size):\n",
    "        super(Dnn_Dependency_Parser, self).__init__()\n",
    "        emb_dim = word_embeddings.shape[1]\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.word_embedding = ## need to add our embeddin - nn.Embedding(word_vocab_size, word_embedding_dim)\n",
    "        # self.word_embedding = nn.Embedding.from_pretrained(word_embeddings, freeze=False)\n",
    "        self.lstm = nn.LSTM(input_size=emb_dim, hidden_size=hidden_dim, num_layers=2, bidirectional=True, batch_first=False)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim*2, tag_vocab_size)\n",
    "\n",
    "        \n",
    "    def forward(self, word_idx_tensor):\n",
    "        embeds = self.word_embedding(word_idx_tensor.to(self.device))   # [batch_size, seq_length, emb_dim]      \n",
    "        lstm_out, _ = self.lstm(embeds.view(embeds.shape[1], 1, -1))    # [seq_length, batch_size, 2*hidden_dim]\n",
    "        tag_space = self.hidden2tag(lstm_out.view(embeds.shape[1], -1)) # [seq_length, tag_dim]\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)                    # [seq_length, tag_dim]\n",
    "        return tag_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUDA_LAUNCH_BLOCKING=1  \n",
    "\n",
    "EPOCHS = 15\n",
    "WORD_EMBEDDING_DIM = 100 ## need to decide if this is the right DIM\n",
    "HIDDEN_DIM = 1000 ## need to decide if this is the right DIM\n",
    "word_vocab_size = len(train.word_idx_mappings)\n",
    "tag_vocab_size = len(train.pos_idx_mappings)\n",
    "\n",
    "##need to decide whihc parameters are relevant\n",
    "model = Dnn_Dependency_Parser(train_dataloader.dataset.word_vectors, HIDDEN_DIM, word_vocab_size, tag_vocab_size)\n",
    "\n",
    "if device == \"cuda\":\n",
    "    model.cuda()\n",
    "\n",
    "# Define the loss function as the Negative Log Likelihood loss (NLLLoss)\n",
    "\n",
    "## no need of that, i implement Negative_log_Likelihood_Loss\n",
    "#loss_function = nn.NLLLoss()\n",
    "\n",
    "# We will be using a simple SGD optimizer to minimize the loss function\n",
    "## we are ok with Adam? need to change?\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "acumulate_grad_steps = 50 # This is the actual batch_size, while we officially use batch_size=1\n",
    "\n",
    "# Training start\n",
    "print(\"Training Started\")\n",
    "accuracy_list = []\n",
    "loss_list = []\n",
    "epochs = EPOCHS\n",
    "for epoch in range(epochs):\n",
    "    acc = 0 # to keep track of accuracy\n",
    "    printable_loss = 0 # To keep track of the loss value\n",
    "    i = 0\n",
    "    for batch_idx, input_data in enumerate(train_dataloader):\n",
    "        i += 1\n",
    "        words_idx_tensor, pos_idx_tensor, sentence_length = input_data\n",
    "        \n",
    "        sentence_scores = model(words_idx_tensor)\n",
    "        sentence_scores = ## need to fix it ----tag_scores.unsqueeze(0).permute(0,2,1)\n",
    "        #print(\"tag_scores shape -\", tag_scores.shape)\n",
    "        #print(\"pos_idx_tensor shape -\", pos_idx_tensor.shape)\n",
    "        loss = Negative_log_Likelihood_Loss(dataset, network_parameters) # need to fix network_parameters\n",
    "        loss = loss / acumulate_grad_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if i % acumulate_grad_steps == 0:\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "        printable_loss += loss.item()## we need to change loss.item() to our lass, i think it will be only loss\n",
    "        _, indices = torch.max(sentence_scores, 1)\n",
    "        # print(\"tag_scores shape-\", tag_scores.shape)\n",
    "        # print(\"indices shape-\", indices.shape)\n",
    "        # acc += indices.eq(pos_idx_tensor.view_as(indices)).mean().item()\n",
    "        acc += torch.mean(torch.tensor(pos_idx_tensor.to(\"cpu\") == indices.to(\"cpu\"), dtype=torch.float))##i think we should fix it\n",
    "    printable_loss = printable_loss / len(train)\n",
    "    acc = acc / len(train)\n",
    "    loss_list.append(float(printable_loss))\n",
    "    accuracy_list.append(float(acc))\n",
    "    test_acc = evaluate()\n",
    "    e_interval = i\n",
    "    print(\"Epoch {} Completed,\\tLoss {}\\tAccuracy: {}\\t Test Accuracy: {}\".format(epoch + 1, np.mean(loss_list[-e_interval:]), np.mean(accuracy_list[-e_interval:]), test_acc))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loss function\n",
    "def Negative_log_Likelihood_Loss(dataset, network_parameters):\n",
    "    loss = 0\n",
    "    for x_i, y_i in dataset:\n",
    "        softmax_score = softmax(y_i)\n",
    "        for head, modifier in y_i:\n",
    "            loss -=(1/absoulte_y_i(y_i))*mat.log(softmax_score(head,modifer))\n",
    "              \n",
    "def absoulte_y_i(y_i):\n",
    "    return len(y_i[:0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate functino- i used the function they share with us,looks ok for me \n",
    "def evaluate(test_dataloader):\n",
    "    acc = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, input_data in enumerate(test_dataloader):\n",
    "            \n",
    "            words_idx_tensor, pos_idx_tensor, sentence_length = input_data  \n",
    "            tag_scores = model(words_idx_tensor)\n",
    "            tag_scores = tag_scores.unsqueeze(0).permute(0,2,1)\n",
    "            \n",
    "            _, indices = torch.max(tag_scores, 1)\n",
    "            acc += torch.mean(torch.tensor(pos_idx_tensor.to(\"cpu\") == indices.to(\"cpu\"), dtype=torch.float))\n",
    "        acc = acc / len(test)\n",
    "    return acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_hw2",
   "language": "python",
   "name": "nlp_hw2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
