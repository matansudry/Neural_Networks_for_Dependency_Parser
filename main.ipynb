{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src import utils\n",
    "from src import bilstm\n",
    "import src.dataset as dset\n",
    "import src.pytorch_utils as ptu\n",
    "import src.chu_liu_edmonds as chu\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "models_path = 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125430/125430 [00:18<00:00, 6905.19it/s]\n",
      "100%|██████████| 25325/25325 [00:03<00:00, 6711.31it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dset.DataSet('data/train.labeled', tqdm_bar=True)\n",
    "# train_dataset = dset.DataSet('data/test.labeled', tqdm_bar=True)\n",
    "test_dataset = dset.DataSet('data/test.labeled', train_dataset=train_dataset, tqdm_bar=True)\n",
    "# comp_dataset = dset.DataSet('data/comp.unlabeled', train_dataset=train_dataset, tagged=False, tqdm_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model version: V1_2.0\n",
      "Number of parameters 2097001 trainable 2097001\n"
     ]
    }
   ],
   "source": [
    "version = 'V1_2.0'\n",
    "save = True\n",
    "\n",
    "model = bilstm.BiLSTM(train_dataset=train_dataset,\n",
    "                      word_embed_dim=100,\n",
    "                      tag_embed_dim=25,\n",
    "                      hidden_dim=125,\n",
    "                      num_layers=2,\n",
    "                      bias=True,\n",
    "                      mlp1_dim=100,\n",
    "                      mlp2_dim=1,\n",
    "                      p_dropout=0.1,\n",
    "                      word_dropout=0.25)\n",
    "\n",
    "checkpoint = ptu.Checkpoint(models_path=models_path,\n",
    "                            version=version,\n",
    "                            model=model,\n",
    "                            score=lambda y_true, y_pred: (np.array(y_true) == np.array(y_pred)).mean(),\n",
    "                            loss_decision_func=utils.loss_decision_func,\n",
    "                            out_decision_func=lambda y_pred, flat_y_pred, mask, padding: flat_y_pred.argmax(axis=1),\n",
    "#                             out_decision_func=test_chu_liu_edmonds,\n",
    "                            seed=42,\n",
    "                            optimizer=torch.optim.Adam,\n",
    "                            criterion=nn.NLLLoss,\n",
    "                            save=save,\n",
    "                            prints=True,\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1/  5 | train_loss 2.19134 | val_loss 2.18516 | train_score 0.30509 | val_score 0.29524 | train_time   0.42 min\n",
      "epoch   2/  5 | train_loss 1.60240 | val_loss 1.60150 | train_score 0.53955 | val_score 0.54721 | train_time   0.85 min\n",
      "epoch   3/  5 | train_loss 1.36056 | val_loss 1.37565 | train_score 0.60301 | val_score 0.60399 | train_time   1.28 min\n",
      "epoch   4/  5 | train_loss 1.26888 | val_loss 1.30515 | train_score 0.61326 | val_score 0.60703 | train_time   1.71 min\n",
      "epoch   5/  5 | train_loss 1.21746 | val_loss 1.27309 | train_score 0.61757 | val_score 0.61137 | train_time   2.15 min\n",
      "epoch   6/100 | train_loss 1.18319 | val_loss 1.24164 | train_score 0.61982 | val_score 0.60885 | train_time   2.53 min\n",
      "epoch   7/100 | train_loss 1.17536 | val_loss 1.23860 | train_score 0.62053 | val_score 0.60944 | train_time   2.92 min\n",
      "epoch   8/100 | train_loss 1.16951 | val_loss 1.23675 | train_score 0.62042 | val_score 0.60873 | train_time   3.30 min\n",
      "epoch   9/100 | train_loss 1.16316 | val_loss 1.23566 | train_score 0.61988 | val_score 0.60817 | train_time   3.69 min\n",
      "epoch  10/100 | train_loss 1.15647 | val_loss 1.23253 | train_score 0.62042 | val_score 0.60715 | train_time   4.08 min\n",
      "epoch  11/100 | train_loss 1.15109 | val_loss 1.23184 | train_score 0.61891 | val_score 0.60553 | train_time   4.47 min\n",
      "epoch  12/100 | train_loss 1.14562 | val_loss 1.23178 | train_score 0.61969 | val_score 0.60517 | train_time   4.85 min\n"
     ]
    }
   ],
   "source": [
    "hyperparam_list = [\n",
    "    {'train_epochs': 5, 'batch_size': 16, 'optimizer_params': {'lr': 1e-3, }, 'lr_decay': 0.0},\n",
    "    {'train_epochs': 95, 'batch_size': 64, 'optimizer_params': {'lr': 4e-4}, 'lr_decay': 0.0},\n",
    "#     {'train_epochs': 5, 'batch_size': 64, 'optimizer_params': {'lr': 1e-4}, 'lr_decay': 0.0},\n",
    "#     {'train_epochs': 35, 'batch_size': 64, 'optimizer_params': {'lr': 1e-5}, 'lr_decay': 0.0},\n",
    "#     {'train_epochs': 5, 'batch_size': 128, 'optimizer_params': {}, 'lr_decay': 0.07},\n",
    "#     {'train_epochs': 50, 'batch_size': 32, 'optimizer_params': {'lr': 4e-4}, 'lr_decay': 0.07},\n",
    "#     {'train_epochs': 50, 'batch_size': 2048, 'optimizer_params': {}, 'lr_decay': 0.07},\n",
    "#     {'train_epochs': 5, 'batch_size': 1024, 'optimizer_params': {'weight_decay': 1e-6}, 'lr_decay': 0.07},\n",
    "#     {'train_epochs': 50, 'batch_size': 2048, 'optimizer_params': {'weight_decay': 1e-6}, 'lr_decay': 0.07},\n",
    "#     {'train_epochs': 50, 'batch_size': 5000, 'optimizer_params': {'weight_decay': 0}, 'lr_decay': 0.05},\n",
    "]\n",
    "\n",
    "for session in hyperparam_list:\n",
    "    checkpoint.train(device=device,\n",
    "                     train_dataset=train_dataset.dataset,\n",
    "                     val_dataset=test_dataset.dataset,\n",
    "                     prints=True,\n",
    "                     epochs_save=5,\n",
    "                     save=save,\n",
    "                     **session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load = ptu.load_model(version=version, models_path=models_path, epoch=-1, seed=42)\n",
    "# loss, score, y_pred, y_true = checkpoint.predict(test_dataset.dataset,\n",
    "#                                                  batch_size=32,\n",
    "#                                                  device=device,\n",
    "#                                                  results=True,\n",
    "#                                                  decision_func=chu.test_chu_liu_edmonds)\n",
    "# print(score)\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# checkpoint.model = checkpoint.model.to(device)\n",
    "# checkpoint.model.train()\n",
    "# batch_size = 1\n",
    "\n",
    "# # loss_sum = np.array([])\n",
    "# # y_pred = np.array([])\n",
    "# # y_true = np.array([])\n",
    "\n",
    "# loader = torch.utils.data.DataLoader(dataset=train_dataset.dataset, batch_size=batch_size, shuffle=True)\n",
    "# for batch in loader:\n",
    "# #     words, tags, lens, y = batch\n",
    "# #     out = checkpoint.model.forward(words.to(device), tags.to(device), lens, prints=True)\n",
    "#     loss, flat_y, flat_out, mask, out, y = utils.loss_decision_func(checkpoint, device, batch, prints=True)\n",
    "\n",
    "# #     loss_sum = np.append(loss_sum, float(loss.data))\n",
    "    \n",
    "# #     y_pred = np.append(y_pred, checkpoint.out_decision_func(out.detach().cpu().numpy()))\n",
    "    \n",
    "# #     y_true = np.append(y_true, batch[-1].detach().cpu().numpy())\n",
    "#     break\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hyperopt as hpo\n",
    "\n",
    "# def Counter():\n",
    "#     for i in range(999999999999):\n",
    "#         yield i\n",
    "\n",
    "# init_space = {\n",
    "    \n",
    "# }\n",
    "\n",
    "# session_space = {\n",
    "    \n",
    "# }\n",
    "\n",
    "# def init_objective(space, save=False):\n",
    "#     score = 0.0\n",
    "#     return - score\n",
    "\n",
    "# def session_objective(space, save=False):\n",
    "#     score = 0.0\n",
    "#     return - score\n",
    "\n",
    "# _ = hpo.fmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_hw2",
   "language": "python",
   "name": "nlp_hw2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
